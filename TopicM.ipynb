{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POCpKQ7Zpz5u",
        "outputId": "3b744acc-8938-459e-94a7-b1fa9cae608c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting warcio\n",
            "  Downloading warcio-1.7.4-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from warcio) (1.16.0)\n",
            "Installing collected packages: warcio\n",
            "Successfully installed warcio-1.7.4\n"
          ]
        }
      ],
      "source": [
        "pip install warcio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF6bfzFUqKzg",
        "outputId": "104910b6-e953-4804-cf47-4aa71f2e4c27"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL-KBEpVqLW-",
        "outputId": "5b055afb-8fb3-4a82-b9f6-7f85894a57bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.127-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.127\n",
            "  Downloading botocore-1.29.127-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.127->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.127->boto3) (1.26.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.127->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.26.127 botocore-1.29.127 jmespath-1.0.1 s3transfer-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "id": "mWfFUlr6qNjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee3957e-80f0-46fb-d03e-2565c8c04613"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=4a517543a2e574cd52f2cef57520cd8223adadc18c5a46b0b2cea632b96817ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, IntegerType, StringType\n",
        "import os\n",
        "import pandas as pd\n",
        "import warcio\n",
        "import re\n",
        "import nltk\n",
        "import gzip\n",
        "import boto3\n",
        "nltk.download('words')\n",
        "from warcio.archiveiterator import ArchiveIterator\n",
        "from pyspark.sql.functions import sum as sql_sum\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF\n",
        "from pyspark.ml.clustering import LDA\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import udf, explode, lit,array\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, ArrayType\n",
        "from nltk.corpus import words\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"myApp\") \\\n",
        "    .config(\"spark.driver.memory\", \"64g\") \\\n",
        "    .config(\"spark.executor.memory\", \"64g\") \\\n",
        "    .getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "T4wkSva_qPhD",
        "outputId": "7f83eb8d-a1e8-479f-e5c0-eb98e5628e06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f4675686f20>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://006d62f9bef6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>myApp</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([\n",
        "    StructField(\"WARC-Type\", StringType(), True),\n",
        "    StructField(\"WARC-Target-URI\", StringType(), True),\n",
        "    StructField(\"WARC-Date\", StringType(), True),\n",
        "    StructField(\"WARC-Record-ID\", StringType(), True),\n",
        "    StructField(\"WARC-Refers-To\", StringType(), True),\n",
        "    StructField(\"WARC-Block-Digest\", StringType(), True),\n",
        "    StructField(\"WARC-Identified-Content-Language\", StringType(), True),\n",
        "    StructField(\"Content-Type\", StringType(), True),\n",
        "    StructField(\"Content-Length\", IntegerType(), True),\n",
        "    StructField(\"Content\", StringType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "yANaMnbcqvRb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ACCESS_KEY=\"\"\n",
        "SECRET_KEY=\"\""
      ],
      "metadata": {
        "id": "BVXTw_njq1Fr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3 = boto3.resource('s3', aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY)\n",
        "for bucket in s3.buckets.all():\n",
        "    print(bucket.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LQSf8eMq1hU",
        "outputId": "a0aab845-03fb-4486-e5df-c3c9b3a11a39"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apbd5254\n",
            "aws-emr-resources-411926377614-us-east-1\n",
            "aws-logs-411926377614-us-east-1\n",
            "elasticbeanstalk-us-east-1-411926377614\n",
            "elasticbeanstalk-us-west-2-411926377614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys=[]\n",
        "for obj in s3.Bucket('apbd5254').objects.all():\n",
        "    keys.append(obj.key)"
      ],
      "metadata": {
        "id": "xsGw7B5Vq2dG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3 = boto3.client('s3', aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY)\n",
        "obj = s3.get_object(Bucket= 'apbd5254', Key= 'keys_novdec_22.txt')"
      ],
      "metadata": {
        "id": "Ksk2cxWqq3ob"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = obj['Body']"
      ],
      "metadata": {
        "id": "uy_kniJEq4ZY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = file.read()"
      ],
      "metadata": {
        "id": "lpuZ-75yq5NY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = file.decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "-oBIHEzCq6GC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = file.splitlines()"
      ],
      "metadata": {
        "id": "847a_Oaqq634"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(200): #1TB\n",
        "    records = []\n",
        "    obj = s3.get_object(Bucket= 'commoncrawl', Key= file[i])\n",
        "    with gzip.open(obj['Body'], 'r') as stream:\n",
        "        for record in ArchiveIterator(stream):\n",
        "            _record = dict(record.rec_headers.headers)\n",
        "            _record['Content'] = record.raw_stream.read().decode('utf-8')\n",
        "            records.append(_record)\n",
        "    records_df = pd.DataFrame(records)\n",
        "    #drop na on uri columns\n",
        "    records_df = records_df.dropna(axis=0, subset=['WARC-Target-URI'])\n",
        "    records_df['WARC-Identified-Content-Language'] = records_df['WARC-Identified-Content-Language'].fillna('not-available')\n",
        "    spark_df = spark.createDataFrame(records_df)\n",
        "    tokenizer = RegexTokenizer(inputCol=\"Content\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "    tokenized_df = tokenizer.transform(spark_df)\n",
        "    stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "    filtered_df = stopwords_remover.transform(tokenized_df)\n",
        "    english_words = set(words.words())\n",
        "    def filter_english_words(words):\n",
        "        return [word for word in words if word.lower() in english_words]\n",
        "    filter_english_words_udf = udf(filter_english_words, ArrayType(StringType()))\n",
        "    filtered_english_words_df = filtered_df.withColumn(\"english_words\", filter_english_words_udf(\"filtered\"))\n",
        "    english_words = set(words.words())\n",
        "    def filter_english_words(words):\n",
        "        return [word for word in words if word.lower() in english_words]\n",
        "    filter_english_words_udf = udf(filter_english_words, ArrayType(StringType()))\n",
        "    filtered_english_words_df = filtered_df.withColumn(\"english_words\", filter_english_words_udf(\"filtered\"))\n",
        "    vectorizer = CountVectorizer(inputCol=\"english_words\", outputCol=\"rawFeatures\", vocabSize=5000, minDF=5.0)\n",
        "    vectorized_df = vectorizer.fit(filtered_english_words_df).transform(filtered_english_words_df)\n",
        "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "    idf_model = idf.fit(vectorized_df)\n",
        "    tfidf_vectors = idf_model.transform(vectorized_df)\n",
        "    num_topics = 5\n",
        "    lda = LDA(k=num_topics, maxIter=10)\n",
        "    lda_model = lda.fit(tfidf_vectors)\n",
        "    vectorizer_model = vectorizer.fit(filtered_english_words_df)\n",
        "    vocab = vectorizer_model.vocabulary\n",
        "    topics = lda_model.describeTopics(maxTermsPerTopic=20)\n",
        "    topic_terms_udf = udf(lambda indices: [vocab[i] for i in indices], ArrayType(StringType()))\n",
        "    topics_with_terms = topics.withColumn(\"topic_terms\", topic_terms_udf(\"termIndices\"))\n",
        "    n = 3\n",
        "    top_topics = topics_with_terms.select(\"topic\", \"topic_terms\").limit(n).collect()\n",
        "    top_topics_list = [(row.topic, row.topic_terms) for row in top_topics]\n",
        "    string = \"The top \" + str(n) + \" topics are: \" + str(top_topics_list)\n",
        "    s3.put_object(\n",
        "    Body=string, \n",
        "    Bucket='apbd5254', \n",
        "    Key='TopicModel/'+str(i) +'.txt'\n",
        "  )"
      ],
      "metadata": {
        "id": "f4EQgYp1sQU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080db4ef-768e-467c-b177-c9b507141db4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-d94ac8db1414>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  records_df['WARC-Identified-Content-Language'] = records_df['WARC-Identified-Content-Language'].fillna('not-available')\n",
            "<ipython-input-15-d94ac8db1414>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  records_df['WARC-Identified-Content-Language'] = records_df['WARC-Identified-Content-Language'].fillna('not-available')\n",
            "<ipython-input-15-d94ac8db1414>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  records_df['WARC-Identified-Content-Language'] = records_df['WARC-Identified-Content-Language'].fillna('not-available')\n"
          ]
        }
      ]
    }
  ]
}